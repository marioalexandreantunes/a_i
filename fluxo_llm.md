# üß† Fluxo de treino de uma LLM/SML

## üóÑÔ∏è Prepara√ß√£o do Dataset

* Coletar um grande conjunto de dados de texto (e.g. livros, artigos, etc.)
* Preparar o dataset para treinamento (e.g. tokeniza√ß√£o, remo√ß√£o de stop words, normaliza√ß√£o de frequ√™ncia, etc.)
* Dividir o dataset em conjuntos de treinamento, valida√ß√£o e teste

Aqui quero deixar um exemplo de um ficheiro formato json que pedi ao ChatGPT para fazer com dados sobre futebol Portugu√™s.
Como podemos verificar √© possivel usar as j√° existentes AIs para 'preparar' dados para fazermos o nosso proprio modelo.

```batch
da-me um exemplo de um ficheiro json com dados sobre futebol portugues, n√£o precisa ser muito grande ,
so com 20 linhas , para usar como dataset para um ML
```

```batch
Claro! Aqui est√° um exemplo de um ficheiro JSON com dados sobre futebol portugu√™s, adequado para uso como
dataset para Machine Learning:
[
    {
        "nome": "Benfica",
        "cidade": "Lisboa",
        "fundacao": 1904,
        "titulos_liga": 37,
        "estadio": "Est√°dio da Luz",
        "capacidade": 64642
    },
    {
        "nome": "Porto",
        "cidade": "Porto",
        "fundacao": 1893,
        "titulos_liga": 30,
        "estadio": "Est√°dio do Drag√£o",
        "capacidade": 50033
    },
    {
        "nome": "Sporting",
        "cidade": "Lisboa",
        "fundacao": 1906,
        "titulos_liga": 19,
        "estadio": "Est√°dio Jos√© Alvalade",
        "capacidade": 50095
    },
    {
        "nome": "Braga",
        "cidade": "Braga",
        "fundacao": 1921,
        "titulos_liga": 0,
        "estadio": "Est√°dio Municipal de Braga",
        "capacidade": 30286
    },
    {
        "nome": "Vit√≥ria de Guimar√£es",
        "cidade": "Guimar√£es",
        "fundacao": 1922,
        "titulos_liga": 0,
        "estadio": "Est√°dio D. Afonso Henriques",
        "capacidade": 30008
    },
    {
        "nome": "Boavista",
        "cidade": "Porto",
        "fundacao": 1903,
        "titulos_liga": 1,
        "estadio": "Est√°dio do Bessa",
        "capacidade": 28263
    },
    {
        "nome": "Mar√≠timo",
        "cidade": "Funchal",
        "fundacao": 1910,
        "titulos_liga": 0,
        "estadio": "Est√°dio dos Barreiros",
        "capacidade": 10932
    },
    {
        "nome": "Belenenses",
        "cidade": "Lisboa",
        "fundacao": 1919,
        "titulos_liga": 1,
        "estadio": "Est√°dio do Restelo",
        "capacidade": 19500
    },
    {
        "nome": "Pa√ßos de Ferreira",
        "cidade": "Pa√ßos de Ferreira",
        "fundacao": 1950,
        "titulos_liga": 0,
        "estadio": "Est√°dio da Mata Real",
        "capacidade": 9125
    },
    {
        "nome": "Rio Ave",
        "cidade": "Vila do Conde",
        "fundacao": 1939,
        "titulos_liga": 0,
        "estadio": "Est√°dio dos Arcos",
        "capacidade": 12815
    }
]
Este exemplo cont√©m informa√ß√µes b√°sicas sobre 10 clubes de futebol portugueses, incluindo nome,
cidade, ano de funda√ß√£o, t√≠tulos da liga, est√°dio e capacidade do est√°dio. √â um dataset simples
mas √∫til para come√ßar a explorar modelos de Machine Learning.
```


## üóÉÔ∏è Pr√©-Processamento de Dados

* Tokeniza√ß√£o: dividir o texto em palavras ou tokens (e.g. utilizando o algoritmo WordPiece)
* Remo√ß√£o de stop words: remover palavras comuns como "the", "and", etc.
* Normaliza√ß√£o: normalizar a frequ√™ncia de palavras e tokens (e.g. utilizando o algoritmo TF-IDF)
* Convers√£o de texto para formato de entrada para o modelo (e.g. sequ√™ncia de tokens)

## üßÆ Escolha do Algoritmo ML

* Selecionar um algoritmo de aprendizado de m√°quina adequado para o problema (e.g. BERT, RoBERTa, etc.)
* Configurar os par√¢metros do algoritmo (e.g. n√∫mero de camadas, n√∫mero de neur√¥nios, etc.)

## üèãÔ∏è Etapas de Treinamento

* Treinamento: repetir as etapas de treino v√°rias vezes, ajustando os par√¢metros do modelo para minimizar a perda
* Valida√ß√£o: avaliar o desempenho do modelo no conjunto de valida√ß√£o para evitar overfitting
* Teste: avaliar o desempenho do modelo no conjunto de teste para avaliar sua generaliza√ß√£o

## üèãÔ∏è Etapas no Treino

1. **Forward Pass**: o modelo processa o input (e.g. uma frase) e produz uma sa√≠da (e.g. uma sequ√™ncia de tokens)
2. **C√°lculo da Perda**: o modelo calcula a diferen√ßa entre a sa√≠da prevista e a sa√≠da real (e.g. a perda de cross-entropy)
3. **Backward Pass**: o modelo ajusta seus par√¢metros internos para reduzir a perda (e.g. ajustando os pesos e bias da rede neural)
4. **Atualiza√ß√£o dos Par√¢metros**: o modelo atualiza seus par√¢metros internos com base na diferen√ßa entre a sa√≠da prevista e a sa√≠da real

## üíæ Ficheiros finais treinados

* O modelo treinado produz ficheiros de sa√≠da que podem ser usados para:
	+ Gerar texto com base em um input (e.g. um prompt)
	+ Realizar tarefas de processamento de linguagem natural (e.g. classifica√ß√£o de texto, gera√ß√£o de resumo, etc.)
	+ Treinar modelos adicionais para tarefas espec√≠ficas

## ‚ùì Como usar esses 'ficheiros'

Existem v√°rias op√ß√µes para alojar os ficheiros treinados de sa√≠da para uso como API. Aqui est√£o algumas op√ß√µes:

1. **Servidor pr√≥prio**: voc√™ pode hospedar os ficheiros em um servidor pr√≥prio, utilizando tecnologias como Apache, Nginx ou IIS. Isso permite que voc√™ tenha controle total sobre a infraestrutura e a seguran√ßa.
2. **Servidores de nuvem**: voc√™ pode utilizar servi√ßos de nuvem como AWS S3, Google Cloud Storage ou Microsoft Azure Blob Storage para armazenar e servir os ficheiros. Esses servi√ßos oferecem escalabilidade, seguran√ßa e facilidade de uso.
3. **Plataformas de API**: voc√™ pode utilizar plataformas de API como AWS API Gateway, Google Cloud Endpoints ou Microsoft Azure API Management para criar e gerenciar APIs. Essas plataformas oferecem recursos como autentica√ß√£o, autoriza√ß√£o e monitoramento.
4. **Servi√ßos de armazenamento de dados**: voc√™ pode utilizar servi√ßos de armazenamento de dados como MongoDB, Cassandra ou PostgreSQL para armazenar e servir os ficheiros. Esses servi√ßos oferecem escalabilidade, seguran√ßa e facilidade de uso.
5. **Servi√ßos de computa√ß√£o em nuvem**: voc√™ pode utilizar servi√ßos de computa√ß√£o em nuvem como AWS Lambda, Google Cloud Functions ou Microsoft Azure Functions para executar o modelo de linguagem e servir os resultados como API. Esses servi√ßos oferecem escalabilidade, seguran√ßa e facilidade de uso.

### Quando escolher uma op√ß√£o, considere fatores como:

* Necessidade de recursos (harware) proderosos para ter uma boa resposta! Modelos que usam 4 bili√µes de parametros* (LLM) em treino precisam de um CPU Intel Core i9-11900K ou um AMD Ryzen 9 5900X, 32Gb Ram e  NVIDIA GeForce RTX 3080 ou um AMD Radeon RX 6800 XT
* Escalabilidade: como o seu modelo de linguagem ir√° crescer, voc√™ precisar√° de uma solu√ß√£o que possa lidar com o aumento do tr√°fego e do armazenamento de dados.
* Seguran√ßa: voc√™ precisar√° garantir que os ficheiros treinados de sa√≠da sejam protegidos contra acesso n√£o autorizado e que a API seja segura para uso.
* Custos: voc√™ precisar√° considerar os custos associados √† escolha da op√ß√£o, incluindo custos de armazenamento, processamento e transfer√™ncia de dados.
* Facilidade de uso: voc√™ precisar√° considerar a facilidade de uso e a documenta√ß√£o da op√ß√£o escolhida.

> Os par√¢metros de um modelo de linguagem s√£o as vari√°veis que s√£o ajustadas durante o treinamento do modelo para melhorar sua capacidade de prever a sa√≠da correta para uma entrada. Mais par√¢metros significam que o modelo tem mais capacidade para aprender e generalizar a partir dos dados de treinamento.
> 100M a 1B (100 milh√µes a 1 bilh√£o) de par√¢metros: Esses s√£o os par√¢metros t√≠picos de um SLM que √© treinado para tarefas de processamento de linguagem natural, como classifica√ß√£o de texto, sentiment analysis e gera√ß√£o de texto.
10M a 100M (10 milh√µes a 100 milh√µes) de par√¢metros: Esses s√£o os par√¢metros t√≠picos de um SLM que √© treinado para tarefas mais espec√≠ficas, como reconhecimento de entidade ou gera√ß√£o de resumo.
1M a 10M (1 milh√£o a 10 milh√µes) de par√¢metros: Esses s√£o os par√¢metros t√≠picos de um SLM que √© treinado para tarefas mais simples, como classifica√ß√£o de texto ou sentiment analysis.

###  Hugging Face 

√© um servi√ßo que fornece uma plataforma para desenvolvedores e cientistas de dados trabalhar com modelos de linguagem e outros tipos de modelos de aprendizado de m√°quina. Eles oferecem uma variedade de recursos, incluindo:

* Um reposit√≥rio de modelos de linguagem pr√©-treinados, incluindo modelos como BERT, RoBERTa e XLNet.
* Uma plataforma para treinar e testar modelos de linguagem.
* Uma API para integrar modelos de linguagem em aplicativos e servi√ßos.
* Ferramentas para processamento de linguagem natural, incluindo tokeniza√ß√£o, paralelismo e gera√ß√£o de texto.

Hugging Face tamb√©m fornece uma variedade de servi√ßos, incluindo:

* Hugging Face Hub: um reposit√≥rio de modelos de linguagem pr√©-treinados e treinados.
* Hugging Face Transformers: uma biblioteca de transformadores de linguagem natural.
* Hugging Face Datasets: uma plataforma para armazenar e compartilhar conjuntos de dados de linguagem natural.

Em resumo, Hugging Face √© um servi√ßo que fornece uma plataforma para desenvolvedores e cientistas de dados trabalhar com modelos de linguagem e outros tipos de modelos de aprendizado de m√°quina. Eles oferecem uma variedade de recursos e servi√ßos para ajudar a desenvolver e implementar aplicativos e servi√ßos que utilizam modelos de linguagem.
