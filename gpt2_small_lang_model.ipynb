{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0fRCtSFcWCpS2jdB0R7ST",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marioalexandreantunes/inteligencia_artificial/blob/main/gpt2_small_lang_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalação de Bibliotecas Necessárias"
      ],
      "metadata": {
        "id": "X6Eslkhz4LqJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0HF_hyG4Fxp"
      },
      "outputs": [],
      "source": [
        "!pip install pyarrow==14.0.2 requests==2.31.0 fsspec==2024.6.1 transformers[torch] datasets torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importação de Bibliotecas"
      ],
      "metadata": {
        "id": "fSLAVuQq4SBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, pipeline\n",
        "from datasets import Dataset\n",
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "md_ywXey4Vcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregar Dados do Arquivo JSON"
      ],
      "metadata": {
        "id": "v-xEVTZL4Yqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "file_path = '/content/dataset.json'\n",
        "df = load_data(file_path)"
      ],
      "metadata": {
        "id": "zjA4w_c74dLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inicializar Tokenizador e Preparar Dados"
      ],
      "metadata": {
        "id": "AMjzyizi4lbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "df['text'] = df['question'] + \" \" + df['answer']\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples, padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "tokenized_datasets = df['text'].apply(lambda x: tokenize_function(x))\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "def tokenize_dataset(dataset):\n",
        "    return dataset.map(lambda x: tokenizer(x['text'], padding=\"max_length\", truncation=True, max_length=512), batched=True, remove_columns=[\"text\", \"question\", \"answer\"])\n",
        "\n",
        "tokenized_dataset = tokenize_dataset(dataset)"
      ],
      "metadata": {
        "id": "PItp-Dkr4mwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adicionar Labels e Dividir Dataset"
      ],
      "metadata": {
        "id": "GeuUQPEO4xOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenized_dataset.map(lambda examples: {'labels': examples['input_ids']}, batched=True)\n",
        "\n",
        "train_test_split = tokenized_dataset.train_test_split(test_size=0.15)\n",
        "train_dataset = train_test_split['train']\n",
        "test_dataset = train_test_split['test']"
      ],
      "metadata": {
        "id": "WKgMBxnh4ztv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função de Agrupamento de Dados"
      ],
      "metadata": {
        "id": "ZCgX32CX46PN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_collator(features):\n",
        "    batch = {}\n",
        "    batch['input_ids'] = torch.tensor([f['input_ids'] for f in features], dtype=torch.long)\n",
        "    batch['attention_mask'] = torch.tensor([f['attention_mask'] for f in features], dtype=torch.long)\n",
        "    batch['labels'] = torch.tensor([f['labels'] for f in features], dtype=torch.long)\n",
        "    return batch"
      ],
      "metadata": {
        "id": "zWMmbRER45u5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inicializar Modelo e Argumentos de Treinamento"
      ],
      "metadata": {
        "id": "3xuDLUg3495x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('distilgpt2')\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        ")"
      ],
      "metadata": {
        "id": "5uCxiARp5Cse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurar o Trainer e Iniciar o Treinamento"
      ],
      "metadata": {
        "id": "6w0F9Tqd5IAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "ob9Obc0f5LfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salvar o Modelo e Tokenizador Treinados"
      ],
      "metadata": {
        "id": "-lx5lFzB5OiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./gpt2-chatbot\")\n",
        "tokenizer.save_pretrained(\"./gpt2-chatbot\")"
      ],
      "metadata": {
        "id": "whrmxbCW5TOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregar Modelo e Tokenizador Treinados"
      ],
      "metadata": {
        "id": "9xztMPNt5Vs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(\"./gpt2-chatbot\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2-chatbot\")"
      ],
      "metadata": {
        "id": "OBe31X0X5Zq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função para Gerar Resposta"
      ],
      "metadata": {
        "id": "cKEuYHbR5cwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_resposta(model, tokenizer, input_text, max_length=50, num_return_sequences=1):\n",
        "    inputs = tokenizer.encode(input_text, return_tensors='pt')\n",
        "    attention_mask = [1] * len(inputs[0])\n",
        "    outputs = model.generate(inputs, attention_mask=torch.tensor([attention_mask]), max_length=max_length, num_return_sequences=num_return_sequences, pad_token_id=tokenizer.eos_token_id)\n",
        "    generated_text = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "AsF5CWZY5gTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exemplo de Uso da Função de Geração de Resposta"
      ],
      "metadata": {
        "id": "bAIltgih5m76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"What are the dimensions of a regulation soccer field?\"\n",
        "resposta = gerar_resposta(model, tokenizer, input_text)\n",
        "print(f\"{resposta}\")"
      ],
      "metadata": {
        "id": "xilbsqMY5qsZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
